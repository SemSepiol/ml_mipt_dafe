{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUF68Fc70QVm"
      },
      "source": [
        "## Семинар 10 - Нейросети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2k0b73c-H6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849a3a9f-b589-4a5f-b819-dac3e0790e7c"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-28T00:59:42.103233Z",
          "start_time": "2020-02-28T00:59:42.099338Z"
        },
        "id": "bX7WKpm20QVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3073d124-bb74-436f-8270-252c7e3084f2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "# warnings.simplefilter('ignore')\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb0b0s_tw0ft"
      },
      "source": [
        "# 1. Вспомним PyTorch\n",
        "\n",
        "Эта часть основана на материалах курса [dlschool](https://www.dlschool.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F-2IcFB0QVu"
      },
      "source": [
        "Нахождение сложной производной\n",
        "\n",
        "Найдите производную по x от функции \n",
        "$$\\sin\\left(\\tan(x)\\frac{x^2}{y} + \\ln(e^{-x^2 + 3}+x^3y)\\right)\\tan(x^2e^{x^9})$$\n",
        "\n",
        "При этом надо пользоваться встроенным в PyTorch autograd. Численное вычисление производной может не дать нужный результат."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-28T00:13:20.890514Z",
          "start_time": "2020-02-28T00:13:20.639022Z"
        },
        "id": "dicy-gHI0QVu"
      },
      "source": [
        "def find_x_derivative(x, y):\n",
        "    # Ваш код здесь\n",
        "    \n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUuuezl4Ant"
      },
      "source": [
        "find_x_derivative(1,21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMhDjJq64GT9"
      },
      "source": [
        "Нахождение косинусной близости\n",
        "\n",
        "Вам даны две матрицы A и B. Необходимо посчитать косинусную близость между строчками матрицы A и столбцами матрицы B. Ответ - матрица чисел, где номер строки - номер строки из матрицы А, а номер столбца - номер столбца из В, от которых бралась косинусная близость.\n",
        "\n",
        "Напомним, что косинусная близость двух векторов - косинус угла между ними. В n-мерном пространстве косинус угла между веткорами удобнее всего через скалярное произведение:\n",
        "$$\\cos(angle(x, y)) = \\frac{x \\cdot y}{\\left\\|x\\right\\| \\left\\|y\\right\\|}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OEhIEkJ4Fqo"
      },
      "source": [
        "def get_cos_sim(A, B):\n",
        "    \"\"\"\n",
        "        A, B - torch float tensors\n",
        "    \"\"\"\n",
        "    # Ваш код здесь\n",
        "    \n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7owb36PL4G1S"
      },
      "source": [
        "A = [[1, -47, 25, -3], [10, 17, -15, 22], [-3, -7, 26, 36], [12, -27, -42, 0]]\n",
        "B = [[-50, -13, 1, 10, 1242], [21, 48, -13, -14, -20], [20, 15, 11, 43, 11], [11, 103, 147, 27, -8]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBv88nsc4aqW"
      },
      "source": [
        "torch.mean(get_cos_sim(A, B))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4WixrwoouOI"
      },
      "source": [
        "# Практика: Погружение в глубокое обучение\n",
        "В семинаре, будем использовать набор данных `fashion_mnist`, загрузим их"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "817LGj2touOJ"
      },
      "source": [
        "from torchvision import datasets,transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1yTnOKlouON"
      },
      "source": [
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = True, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y_gHUUaouOQ"
      },
      "source": [
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = False, download = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-yhD9MIouOT"
      },
      "source": [
        "num_classes = len(trainset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwATUm42gW3I"
      },
      "source": [
        "trainset.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw3moMZ4ouOW"
      },
      "source": [
        "x_train = trainset.train_data\n",
        "y_train = trainset.train_labels\n",
        "\n",
        "x_test = testset.train_data\n",
        "y_test = testset.train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydrltpE936w_"
      },
      "source": [
        "x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOoVSZBouOZ"
      },
      "source": [
        "fig = plt.figure(figsize=(15,5))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    idx = np.where(y_train[:]==i)[0]\n",
        "    features_idx = x_train[idx,::]\n",
        "    img_num = np.random.randint(features_idx.shape[0])\n",
        "    im = features_idx[img_num]\n",
        "    ax.set_title(trainset.classes[i])\n",
        "    plt.imshow(im, cmap='gray_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEwx6Wp4ouOc"
      },
      "source": [
        "### Проведем небольшие предобработки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1swzXaqouOc"
      },
      "source": [
        "x_train_flat = x_train.flatten(start_dim=1).float()\n",
        "x_test_flat = x_test.flatten(start_dim=1).float()\n",
        "print(f'Была размерность: {x_train.shape}, стала: {x_train_flat.shape}')\n",
        "print(f'Была размерность: {x_test.shape}, стала: {x_test_flat.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eXoS2gMouOf"
      },
      "source": [
        "D_out =  # Ваш код здесь\n",
        "D_in = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C-YR6PGouOh"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, 128),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(128, 10),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(10, D_out),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uv5d7YFouOp"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(D_in, 128)\n",
        "        self.act1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "        self.act2 = torch.nn.Sigmoid()\n",
        "        self.fc3 = torch.nn.Linear(10, D_out)\n",
        "        self.act3 = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "        return x\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL0biu-EouOr"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1JmI-2fouOu"
      },
      "source": [
        "# Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "# override the __call__ operator so you can call them like functions. When\n",
        "# doing so you pass a Tensor of input data to the Module and it produces\n",
        "# a Tensor of output data.\n",
        "y_pred = model(x_train_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJtuDQ6sjvea"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5JD6xWqouOw"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWHhi6hTiVOB"
      },
      "source": [
        "# Compute and print loss. We pass Tensors containing the predicted and true\n",
        "# values of y, and the loss function returns a Tensor containing the\n",
        "# loss.\n",
        "loss_old = loss_fn(y_pred, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTU0UUM56ii6"
      },
      "source": [
        "loss_old"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK5o-0gNihzV"
      },
      "source": [
        "acc_old = accuracy_score(y_train.numpy(), y_pred.argmax(dim=1).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWwixxeJ7ckE"
      },
      "source": [
        "acc_old"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM8oRGwlih2f"
      },
      "source": [
        "# Zero the gradients before running the backward pass.\n",
        "model.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DqxPMqRih5L"
      },
      "source": [
        "# Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "# parameters of the model. Internally, the parameters of each Module are stored\n",
        "# in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "# all learnable parameters in the model.\n",
        "loss_old.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loqaoy8Zi1PH"
      },
      "source": [
        "learning_rate = 1e-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uinN4Hen8x-D"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1fPGyDKiw-U"
      },
      "source": [
        "# Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "# we can access its gradients like we did before.\n",
        "with torch.no_grad():\n",
        "  # Ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSIGz0wnixBE"
      },
      "source": [
        "y_pred = model(x_train_flat.float())\n",
        "loss_new = loss_fn(y_pred, y_train)\n",
        "step = loss_new.item()-loss_old.item()\n",
        "\n",
        "acc_new = accuracy_score(y_train.numpy(), y_pred.argmax(dim=1).numpy())\n",
        "\n",
        "print(f'Лосс: {loss_old.item()} -> {loss_new.item()}. Step {step} ')\n",
        "print(f'Accuracy: {acc_old} -> {acc_new}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFGhystlouO1"
      },
      "source": [
        "def batch_train(model, loss_fn, learning_rate, x, y):\n",
        "  # Ваш код здесь\n",
        "    \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG1SImTaouO3"
      },
      "source": [
        "def train(model, n_epochs, batch_size, learning_rate,  X, y, X_test, y_test):\n",
        "    acc_train_all = []\n",
        "    loss_train_all = []\n",
        "    acc_test_all = []\n",
        "    loss_test_all = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        permutation = torch.randperm(X.size()[0])\n",
        "\n",
        "        for i in tqdm(range(0,X.float().size()[0], batch_size)):\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_x, batch_y = X[indices], y[indices]\n",
        "            batch_train(model, loss_fn, learning_rate, batch_x, batch_y)\n",
        "\n",
        "        y_test_pred = model(X_test)\n",
        "        y_train_pred = model(X)\n",
        "\n",
        "\n",
        "        acc_train = accuracy_score(y.numpy(), y_train_pred.argmax(dim=1).numpy())\n",
        "        loss_train = loss_fn(y_train_pred, y).detach().numpy() \n",
        "        acc_test = accuracy_score(y_test.numpy(), y_test_pred.argmax(dim=1).numpy())\n",
        "        loss_test = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "\n",
        "        acc_train_all = np.append(acc_train_all, acc_train)\n",
        "        loss_train_all = np.append(loss_train_all, loss_train)\n",
        "        acc_test_all = np.append(acc_test_all, acc_test)\n",
        "        loss_test_all = np.append(loss_test_all, loss_test)\n",
        "\n",
        "\n",
        "        print(f'Epoch {epoch}: \\n Accuracy - train: {acc_train} | test: {acc_test} \\n Loss - train: {loss_train} | test: {loss_test}')\n",
        "        \n",
        "    return(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tvQm6qs8ouO6"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000 \n",
        "learning_rate = 1e-1\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = \\\n",
        "          train(model, n_epochs, batch_size, learning_rate, x_train_flat, y_train, x_test_flat, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUytpKIuouO9"
      },
      "source": [
        "def vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all):\n",
        "    fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "\n",
        "    plt.plot(loss_train_all, label='loss')\n",
        "    plt.plot(loss_test_all, label='val_loss')\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(acc_train_all, label='acc')\n",
        "    plt.plot(acc_test_all, label='val_acc')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rchVUmigouO_"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdDt8drzouPE"
      },
      "source": [
        "## Что мы можем улучшить? \n",
        "- Отнормировать признаки\n",
        "- Заменить сигмоиды на ReLu\n",
        "- Задать правила инициации весов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWTYU3xouPE"
      },
      "source": [
        "### Нормировка\n",
        "![picture](https://drive.google.com/uc?export=view&id=1kSw5ceu5iexG5DIPkhHGtXUepZtl9t6Q)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDCj3aJBouPF"
      },
      "source": [
        "# Ваш код здесь\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkqCvSZzouPJ"
      },
      "source": [
        "x_train_norm.max(), x_train_norm.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8efS67TuNmA"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 2028 \n",
        "learning_rate = 1e-2\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model, n_epochs, batch_size, learning_rate,\n",
        "                                                                   x_train_norm, y_train, x_test_norm, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm1OG8zyuNmC"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4BICv8uouPM"
      },
      "source": [
        "### Инициациия весов\n",
        "__Случайно__  \n",
        "$ w = a * random$, но тогда если $a \\gg 1$, то на выходе $b\\gg1$ и если $a \\ll 1 $, то $b \\approx 0 $  \n",
        "\n",
        "__Xavier__  \n",
        "$a = \\frac{1}{\\sqrt{n}}$, где $n$ - кол-во нейронов на входе\n",
        "\n",
        "__He__  \n",
        "$a = \\frac{1}{\\sqrt{\\frac{n}{2}}}$, где $n$ - кол-во нейронов на входе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XswYTN_LouPM"
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == torch.nn.Linear:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ4-dwjOouPO"
      },
      "source": [
        "Примените к модели  функцию инициации весов с помощью метода .apply()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPFssk4ouPP"
      },
      "source": [
        "model_2 =  model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcBd7Ot3ouPR"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 2028 \n",
        "learning_rate = 1e-2\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_2, n_epochs, batch_size, learning_rate,\n",
        "                                                                   x_train_norm, y_train, x_test_norm, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GnH4Sj6ouPT"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo3z_0ojqYaN"
      },
      "source": [
        "### Функции активации\n",
        "![picture](https://drive.google.com/uc?export=view&id=1pHhpRQNXHnFCyVyvJJJtqMkLhJInT1i3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkasCLSsAoUR"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(D_in, 128)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "        self.fc3 = torch.nn.Linear(10, D_out)\n",
        "        self.act3 = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "        return x\n",
        "\n",
        "model_3 = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgMmIa0wGUD"
      },
      "source": [
        "n_epochs = 20\n",
        "batch_size = 2028 \n",
        "learning_rate = 1e-2\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_3, n_epochs, batch_size, learning_rate,\n",
        "                                                                   x_train_norm, y_train, x_test_norm, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mezplo7wGUH"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA9GBCWtouPW"
      },
      "source": [
        "## Влияние скорости обучения\n",
        "Посмотрим, как влияет параметр `learning_rate` на качество нашей модели на обучающей выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWt_4O03ouPW"
      },
      "source": [
        "learning_rates = [1e+1, 1e-2, 1e-3, 1e-5, 1e-10] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8QSOGDouPZ"
      },
      "source": [
        "voc_loss_train = {}\n",
        "batch_size = 5000\n",
        "\n",
        "for i in learning_rates:\n",
        "    model_3.apply(init_weights)\n",
        "    acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_3, 25, batch_size, i,\n",
        "                                                                       x_train_flat, y_train, x_test_flat, y_test)\n",
        "    voc_loss_train[i] = loss_train_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uw84G_DouPb"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "for i in voc_loss_train.keys():\n",
        "    plt.plot(voc_loss_train[i], label=f'{i}')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUS8D8PdouPe"
      },
      "source": [
        "## Влияние метода оптимизации градиентного спуска"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSPLQfCrouPe"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1D3hA1C9MCx5eNRHb2yo2W_4wJjT0IjHv)\n",
        "\n",
        "#### Momentum\n",
        "Вместо того, чтобы использовать только градиент текущего шага, мы будем накапливать импульс градиента прошлых шагов для определения направления движения. \n",
        "В связи со стохастической природой, обновления градиента происходят \"зигзагообразно\", с помощью момента мы усиливаем движение вдоль основного направления. На практике коэффициент у момента инициализируется на уровне 0,5 и постепенно увеличивается до 0,9 в течение нескольких эпох. \n",
        "  \n",
        "#### RMSProp (Root Mean Square Propogation)   \n",
        "Мы обновляяем меньше веса, которые слишком часто обновляются, и будем использовать усреднённый по истории квадрат градиента.\n",
        "\n",
        "#### Adam (Adaptive moment estimation)\n",
        "Cочетает в себе и идею накопления движения и идею более слабого обновления весов для типичных признаков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiNYQh0fouPe"
      },
      "source": [
        "optimizer = torch.optim.SGD(model_3.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1WqtKJouPh"
      },
      "source": [
        "def batch_train(model, x, y):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    #    with torch.no_grad():\n",
        "    #    for param in model.parameters():\n",
        "    #        param -= learning_rate * param.grad\n",
        "    optimizer.step()\n",
        "    return(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l1nZ_qEQouPj"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "model_2.apply(init_weights)\n",
        "loss_train_sgd = []\n",
        "\n",
        "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.001, momentum=0.0)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    permutation = torch.randperm(x_train_norm.size()[0])\n",
        "\n",
        "    for i in tqdm(range(0,x_train_norm.float().size()[0], batch_size)):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = x_train_norm[indices], y_train[indices]\n",
        "        batch_train(model_2, batch_x, batch_y)\n",
        "\n",
        "    y_test_pred = model_2(x_test_norm)\n",
        "    loss_train = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "    print(f'Epoch: {epoch} loss {loss_train}')\n",
        "    loss_train_sgd = np.append(loss_train_sgd, loss_train)\n",
        "\n",
        "    \n",
        "model_2.apply(init_weights)\n",
        "loss_train_sgd_moment = []\n",
        "\n",
        "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    permutation = torch.randperm(x_train_norm.size()[0])\n",
        "\n",
        "    for i in tqdm(range(0,x_train_norm.float().size()[0], batch_size)):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = x_train_norm[indices], y_train[indices]\n",
        "        batch_train(model_2, batch_x, batch_y)\n",
        "\n",
        "    y_test_pred = model_2(x_test_norm)\n",
        "    loss_train = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "    print(f'Epoch: {epoch} loss {loss_train}')\n",
        "    loss_train_sgd_moment = np.append(loss_train_sgd_moment, loss_train)\n",
        "    \n",
        "    \n",
        "\n",
        "model_2.apply(init_weights)\n",
        "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
        "loss_train_adam = []\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    permutation = torch.randperm(x_train_norm.size()[0])\n",
        "\n",
        "    for i in tqdm(range(0,x_train_norm.float().size()[0], batch_size)):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = x_train_norm[indices], y_train[indices]\n",
        "        batch_train(model_2, batch_x, batch_y)\n",
        "\n",
        "    y_test_pred = model_2(x_test_norm)\n",
        "    loss_train = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "    print(f'Epoch: {epoch} loss {loss_train}')\n",
        "    loss_train_adam = np.append(loss_train_all, loss_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN6ZsupyouPm"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "plt.plot(loss_train_sgd, label='SGD')\n",
        "plt.plot(loss_train_sgd_moment, label='SGD with momentum')\n",
        "plt.plot(loss_train_adam, label='Adam')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGry9LYouPo"
      },
      "source": [
        "# Ссылки\n",
        "- [Курс \"Deep learning на пальцах\", лекция 4](https://youtu.be/tnrbx7V9RbA)\n",
        "- [Статья: Оптимизация градиентного спуска](http://ruder.io/optimizing-gradient-descent/)\n",
        "- [Статья: Методы оптимизации нейронных сетей](https://habr.com/ru/post/318970/)"
      ]
    }
  ]
}